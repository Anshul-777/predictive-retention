# -*- coding: utf-8 -*-
"""Customer Churn Predictor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F-Q9w-haBcX6AIDlarUqTet2sSE5Z0Mv

# Project : Customer Churn Predictor

Develop a machine learning model to predict customer churn using the 'Telco Customer Churn' dataset from Kaggle, demonstrating the application of gradient descent through a Logistic Regression model, including data preprocessing, model training, hyperparameter tuning, evaluation, and a conceptual 3D visualization of the gradient descent optimization process.

The 'Telco Customer Churn' dataset from Kaggle has been selected for this project. The problem is defined as predicting customer churn, which is a binary classification task.

**Kaggle Dataset Identifier:** `blastchar/telco-customer-churn`

# Project CCP

## Configure Kaggle API
"""

# Create the .kaggle directory if it doesn't exist
!mkdir -p ~/.kaggle

# Move the uploaded kaggle.json file to the .kaggle directory
!mv kaggle.json ~/.kaggle/

# Set appropriate file permissions for kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

print("Kaggle API setup commands executed.")

"""## Download and Load Data"""

import pandas as pd

# Download the dataset
!kaggle datasets download -d blastchar/telco-customer-churn

# Unzip the downloaded file
!unzip telco-customer-churn.zip

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')

# Display the first few rows of the DataFrame
df.head()

"""## Exploratory Data Analysis (EDA)"""

print(df.info())

import numpy as np

# Convert 'TotalCharges' to numeric, coercing errors to NaN
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Calculate the sum of missing values for each column
print("\nMissing values per column:")
print(df.isnull().sum())

# Handle missing values in 'TotalCharges' by filling with the median
# The number of missing values is small (11 out of 7043), so filling with median is a reasonable approach.
df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())

# Verify that there are no more missing values in 'TotalCharges'
print("\nMissing values after imputation:")
print(df.isnull().sum().loc['TotalCharges'])

# Generate descriptive statistics for numerical columns
print("\nDescriptive statistics for numerical columns:")
print(df.describe())

print("\nDistribution of the target variable 'Churn':")
print(df['Churn'].value_counts())

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(6, 4))
sns.countplot(x='Churn', data=df, hue='Churn', palette='viridis', legend=False)
plt.title('Distribution of Customer Churn')
plt.xlabel('Churn')
plt.ylabel('Number of Customers')
plt.show()

numerical_cols = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']

plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols):
    plt.subplot(2, 2, i + 1)
    sns.histplot(df[col], kde=True, bins=30, color='skyblue')
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
plt.tight_layout()
plt.show()

categorical_cols = df.select_dtypes(include='object').columns.tolist()
# Exclude 'customerID' and 'Churn' as they are not features for distribution analysis
categorical_cols.remove('customerID')
categorical_cols.remove('Churn')

# Determine the number of rows and columns for subplots
num_cols = len(categorical_cols)
num_rows = (num_cols + 2) // 3 # Roughly 3 plots per row

plt.figure(figsize=(18, num_rows * 5))
for i, col in enumerate(categorical_cols):
    plt.subplot(num_rows, 3, i + 1)
    sns.countplot(x=col, data=df, palette='viridis', hue=col, legend=False)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=45, ha='right') # Rotate labels for better readability
plt.tight_layout()
plt.show()

"""## Data Preprocessing"""

df = df.drop('customerID', axis=1)
print("Dropped 'customerID' column.")
print(df.head())

df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})
print("Converted 'Churn' column to numerical format.")
print(df['Churn'].value_counts())

categorical_features = df.select_dtypes(include='object').columns.tolist()
numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# 'Churn' is now numerical, ensure it's not treated as a categorical feature
# Also ensure 'SeniorCitizen' is treated as a numerical feature for scaling, despite its binary nature

print("Identified Categorical Features:", categorical_features)
print("Identified Numerical Features:", numerical_features)

"""#### One Hot Encoding"""

from sklearn.preprocessing import OneHotEncoder

# Initialize OneHotEncoder with drop='first' to avoid multicollinearity
encoder = OneHotEncoder(drop='first', sparse_output=False)

# Fit and transform the categorical features
encoded_features = encoder.fit_transform(df[categorical_features])

# Create a DataFrame from the encoded features with appropriate column names
encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))

print("One-hot encoded categorical features.")
print(encoded_df.head())

"""#### Standard Scaler"""

from sklearn.preprocessing import StandardScaler

# Initialize StandardScaler
scaler = StandardScaler()

print("StandardScaler initialized.")

numerical_features_to_scale = [feature for feature in numerical_features if feature != 'Churn']

# Fit and transform the numerical features (excluding 'Churn')
scaled_features = scaler.fit_transform(df[numerical_features_to_scale])

# Create a DataFrame from the scaled features with appropriate column names
scaled_df = pd.DataFrame(scaled_features, columns=numerical_features_to_scale)

print("Numerical features scaled.")
print(scaled_df.head())

import pandas as pd

# Extract the 'Churn' column separately
churn_target = df['Churn']

# Concatenate scaled numerical features, encoded categorical features, and the target variable
preprocessed_df = pd.concat([scaled_df, encoded_df, churn_target], axis=1)

print("Final preprocessed DataFrame created.")
print(preprocessed_df.head())
print(f"Shape of preprocessed DataFrame: {preprocessed_df.shape}")

"""## Feature Engineering"""

addon_cols = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']

# Map 'Yes' to 1 and 'No' to 0 for the addon service columns
for col in addon_cols:
    df[col] = df[col].map({'Yes': 1, 'No': 0, 'No internet service': 0})

# Create 'Num_Addon_Services' by summing these columns
df['Num_Addon_Services'] = df[addon_cols].sum(axis=1)

print("Created 'Num_Addon_Services' feature.")
print(df[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Num_Addon_Services']].head())

df['Has_Internet_No_Security'] = (
    (df['InternetService'] != 'No') &
    (df['OnlineSecurity'] == 0) &
    (df['TechSupport'] == 0)
).astype(int)

print("Created 'Has_Internet_No_Security' feature.")
print(df[['InternetService', 'OnlineSecurity', 'TechSupport', 'Has_Internet_No_Security']].head())

numerical_features.append('Num_Addon_Services')

print("Updated Numerical Features:", numerical_features)

numerical_features.append('Has_Internet_No_Security')

print("Updated Numerical Features:", numerical_features)

from sklearn.preprocessing import StandardScaler
import pandas as pd

# Ensure 'Churn' is not in the list of features to be scaled
numerical_features_to_scale = [feature for feature in numerical_features if feature != 'Churn']

# Initialize StandardScaler (or re-initialize if needed, though existing one can be used)
scaler = StandardScaler()

# Fit and transform the updated numerical features
scaled_features = scaler.fit_transform(df[numerical_features_to_scale])

# Create a DataFrame from the scaled features with appropriate column names
scaled_df = pd.DataFrame(scaled_features, columns=numerical_features_to_scale)

print("Updated numerical features scaled.")
print(scaled_df.head())
print(f"Shape of scaled_df: {scaled_df.shape}")

from sklearn.preprocessing import OneHotEncoder

# Redefine categorical features based on the current df's dtypes
categorical_features = df.select_dtypes(include='object').columns.tolist()

# Initialize OneHotEncoder with drop='first' to avoid multicollinearity
encoder = OneHotEncoder(drop='first', sparse_output=False)

# Fit and transform the updated categorical features
encoded_features = encoder.fit_transform(df[categorical_features])

# Create a DataFrame from the encoded features with appropriate column names
encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))

print("Updated categorical features one-hot encoded.")
print(encoded_df.head())
print(f"Shape of encoded_df: {encoded_df.shape}")

import pandas as pd

# Concatenate scaled numerical features, encoded categorical features, and the target variable
preprocessed_df = pd.concat([scaled_df, encoded_df, churn_target], axis=1)

print("Final preprocessed DataFrame with new features created.")
print(preprocessed_df.head())
print(f"Shape of preprocessed DataFrame: {preprocessed_df.shape}")

"""## Model Selection and Training (Logistic Regression)"""

X = preprocessed_df.drop('Churn', axis=1)
y = preprocessed_df['Churn']

print("Features (X) and target (y) separated.")
print("Shape of X:", X.shape)
print("Shape of y:", y.shape)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Dataset split into training and testing sets.")
print(f"Shape of X_train: {X_train.shape}")
print(f"Shape of X_test: {X_test.shape}")
print(f"Shape of y_train: {y_train.shape}")
print(f"Shape of y_test: {y_test.shape}")

"""Import `LogisticRegression` from `sklearn.linear_model` and instantiate the model."""

from sklearn.linear_model import LogisticRegression

# Instantiate the Logistic Regression model
model = LogisticRegression(random_state=42, solver='liblinear') # Using 'liblinear' for smaller datasets and L1/L2 regularization

print("Logistic Regression model instantiated.")

"""Train the instantiated `LogisticRegression` model using the training data (`X_train`, `y_train`) with the `.fit()` method."""

model.fit(X_train, y_train)

print("Logistic Regression model trained on the training data.")

"""## Hyperparameter Tuning"""

from sklearn.model_selection import GridSearchCV

print("GridSearchCV imported.")

"""Define a dictionary for the hyperparameter grid, including `C` and `solver` parameters for Logistic Regression."""

param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'solver': ['liblinear', 'lbfgs'] # 'lbfgs' is default, 'liblinear' is good for small datasets and allows L1/L2
}

print("Hyperparameter grid defined.")

"""Instantiate a `LogisticRegression` model with `random_state=42` to ensure reproducibility. The solver will be set to 'liblinear' as it's efficient for smaller datasets and supports both L1/L2 regularization."""

from sklearn.linear_model import LogisticRegression

# Instantiate the Logistic Regression model
model = LogisticRegression(random_state=42, solver='liblinear') # Using 'liblinear' for smaller datasets and L1/L2 regularization

print("Logistic Regression model instantiated.")

"""Initialize `GridSearchCV` with the instantiated `LogisticRegression` model, the defined `param_grid`, `cv=5` for cross-validation, and `scoring='accuracy'`. I will also set `n_jobs=-1` to utilize all available processors."""

from sklearn.model_selection import GridSearchCV

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)

print("GridSearchCV initialized.")

"""Fit `GridSearchCV` to the training data (`X_train`, `y_train`) to perform the hyperparameter search."""

grid_search.fit(X_train, y_train)

print("GridSearchCV fitting complete.")

"""Print the best hyperparameters found by the search using `grid_search.best_params_`."""

print("Best hyperparameters found:", grid_search.best_params_)

"""Print the best cross-validation score achieved with the best parameters using `grid_search.best_score_`."""

print("Best cross-validation score:", grid_search.best_score_)

"""## Model Evaluation"""

best_estimator = grid_search.best_estimator_

# Make predictions on the test set
y_pred = best_estimator.predict(X_test)

# Predict probabilities for the positive class (class 1)
y_pred_proba = best_estimator.predict_proba(X_test)[:, 1]

print("Best estimator retrieved and predictions made on the test set.")

"""Import `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, and `roc_auc_score` from `sklearn.metrics`."""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_proba)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print(f"ROC AUC Score: {roc_auc:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

"""## Visualize Model Performance"""

from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay
import matplotlib.pyplot as plt

# Create a figure with three subplots
fig, axes = plt.subplots(1, 3, figsize=(20, 6))

# Plot the Confusion Matrix
ConfusionMatrixDisplay.from_estimator(best_estimator, X_test, y_test, cmap='Blues', ax=axes[0])
axes[0].set_title('Confusion Matrix')

# Plot the ROC Curve
RocCurveDisplay.from_estimator(best_estimator, X_test, y_test, ax=axes[1])
axes[1].set_title('ROC Curve')

# Plot the Precision-Recall Curve
PrecisionRecallDisplay.from_estimator(best_estimator, X_test, y_test, ax=axes[2])
axes[2].set_title('Precision-Recall Curve')

# Adjust layout and display plots
plt.tight_layout()
plt.show()

"""## Conceptual 3D Gradient Descent Visualization"""

import numpy as np

# 1. Define a simplified, convex 3D loss function and its partial derivatives
# Using f(x, y) = x^2 + y^2 for simplicity
def loss_function(x, y):
    return x**2 + y**2

# Gradient of the loss function: df/dx = 2x, df/dy = 2y
def gradient_function(x, y):
    return np.array([2*x, 2*y])

print("Loss function and gradient function defined.")

"""Initialize random starting points for the parameters `theta_x` and `theta_y` and define hyperparameters for gradient descent, such as `learning_rate` and `iterations`."""

import numpy as np

# 2. Initialize random starting points for parameters and define hyperparameters
# Random starting points for theta_x and theta_y
theta_x_initial = np.random.uniform(-5, 5)
theta_y_initial = np.random.uniform(-5, 5)

# Gradient descent hyperparameters
learning_rate = 0.1
iterations = 50

print(f"Initial parameters: theta_x = {theta_x_initial:.2f}, theta_y = {theta_y_initial:.2f}")
print(f"Learning rate: {learning_rate}")
print(f"Iterations: {iterations}")

"""Implement the gradient descent algorithm. In a loop, I will iteratively update the parameters `theta_x` and `theta_y` using the `gradient_function` and `learning_rate`. I will store the parameter values and the corresponding `loss_function` output at each step to visualize the optimization path."""

import numpy as np

# 3. Implement the gradient descent algorithm and store the path

# Initialize current parameters with the initial random points
theta_x = theta_x_initial
theta_y = theta_y_initial

# Lists to store the history of parameters and loss values
param_history = []
loss_history = []

for i in range(iterations):
    # Calculate the current loss
    current_loss = loss_function(theta_x, theta_y)

    # Store current parameters and loss
    param_history.append((theta_x, theta_y))
    loss_history.append(current_loss)

    # Calculate the gradient at the current parameters
    gradient = gradient_function(theta_x, theta_y)

    # Update parameters using the gradient descent rule
    theta_x = theta_x - learning_rate * gradient[0]
    theta_y = theta_y - learning_rate * gradient[1]

# Store the final parameters and loss after all iterations
param_history.append((theta_x, theta_y))
loss_history.append(loss_function(theta_x, theta_y))

print("Gradient descent algorithm implemented. Parameter and loss history stored.")
print(f"Final parameters: theta_x = {theta_x:.2f}, theta_y = {theta_y:.2f}")
print(f"Final loss: {loss_function(theta_x, theta_y):.2f}")

"""Create a 3D plot to visualize the loss surface of the defined `loss_function`. This involves generating a grid of x and y values using `meshgrid` and calculating the corresponding loss values."""

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# 4. Create a 3D plot to visualize the loss surface
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Generate a grid of x and y values
x_vals = np.linspace(-5, 5, 100)
y_vals = np.linspace(-5, 5, 100)
X, Y = np.meshgrid(x_vals, y_vals)
Z = loss_function(X, Y)

# Plot the surface
ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.6)

print("3D loss surface plot created.")

"""Overlay the path taken by the gradient descent algorithm on the 3D loss surface plot, showing how the parameters converged towards the minimum. I will use the `param_history` and `loss_history` lists generated in the previous step."""

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# Extract x, y, and z values from the history lists
param_x_history = [p[0] for p in param_history]
param_y_history = [p[1] for p in param_history]
loss_z_history = loss_history

# Plot the optimization path
ax.plot(param_x_history, param_y_history, loss_z_history, marker='o', color='red', markersize=5, label='GD Path')

print("Optimization path overlaid on the 3D loss surface.")

"""Add appropriate labels for the x, y, and z axes and a title to the plot to enhance readability."""

import matplotlib.pyplot as plt

# Add labels and title
ax.set_xlabel('Parameter X')
ax.set_ylabel('Parameter Y')
ax.set_zlabel('Loss')
ax.set_title('Conceptual 3D Gradient Descent Visualization')

plt.legend()
plt.show()

print("Labels and title added to the 3D plot.")

import matplotlib.pyplot as plt

# Add labels and title
ax.set_xlabel('Parameter X')
ax.set_ylabel('Parameter Y')
ax.set_zlabel('Loss')
ax.set_title('Conceptual 3D Gradient Descent Visualization')

ax.legend() # Changed from plt.legend() to ax.legend()
plt.show()

print("Labels and title added to the 3D plot.")

"""### Conceptual 3D Gradient Descent Visualization Explanation

The 3D plot above provides a **conceptual visualization** of how gradient descent works. It uses a simplified, convex loss function (a quadratic bowl) with only two parameters (Parameter X and Parameter Y) to demonstrate the optimization process. This allows us to visually trace the path taken by the algorithm as it iteratively updates the parameters to find the minimum of the loss surface.

In real-world machine learning models, such as the Logistic Regression model used in this project, the loss surface is significantly more complex and exists in a much higher-dimensional space (equal to the number of features plus one for the intercept). It is impossible to directly visualize such high-dimensional surfaces in 3D.

However, the core mechanism remains the same: the algorithm calculates the gradient (the direction of the steepest ascent) of the loss function with respect to the parameters and then moves in the opposite direction (steepest descent) by a magnitude determined by the learning rate. This iterative process continues until the algorithm converges to a local (or global, for convex functions) minimum, where the loss is minimized.

This simplified visualization helps in understanding:
*   **The Loss Surface**: How the loss varies with changes in parameters.
*   **Iterative Updates**: The step-by-step nature of parameter adjustments.
*   **Convergence**: How the algorithm eventually reaches a point of minimal loss.

This conceptual understanding is directly applicable to how the Logistic Regression model was trained, where an optimizer (like 'liblinear' or 'lbfgs' used in `sklearn`) internally performs a form of gradient descent to find the optimal coefficients that minimize the logistic loss function.

## Adjust Plotly Figure Size
"""

import plotly.graph_objects as go
import numpy as np

# Reuse the previously defined loss_function and the history of parameters
# Assuming loss_function, param_history, and loss_history are available from previous executions.

# Generate a grid of x and y values for the surface
x_surface = np.linspace(-5, 5, 50)
y_surface = np.linspace(-5, 5, 50)
X_surface, Y_surface = np.meshgrid(x_surface, y_surface)
Z_surface = loss_function(X_surface, Y_surface)

# Create the 3D surface plot
surface_trace = go.Surface(x=X_surface, y=Y_surface, z=Z_surface, colorscale='viridis', opacity=0.7, name='Loss Surface')

# Extract x, y, z coordinates for the gradient descent path
path_x = [p[0] for p in param_history]
path_y = [p[1] for p in param_history]
path_z = loss_history

# Create the scatter plot for the gradient descent path
path_trace = go.Scatter3d(x=path_x, y=path_y, z=path_z, mode='lines+markers', marker=dict(size=4, color='red'), line=dict(color='red', width=4), name='GD Path')

# Create the figure and add traces
fig = go.Figure(data=[surface_trace, path_trace])

# Update layout for better visualization on narrower screens
fig.update_layout(
    title='Interactive 3D Gradient Descent Visualization',
    scene=dict(
        xaxis_title='Parameter X',
        yaxis_title='Parameter Y',
        zaxis_title='Loss'
    ),
    margin=dict(l=0, r=0, b=0, t=40), # Removes side/bottom margins
    autosize=True # Scales automatically to the container width
)

# Display the interactive plot
fig.show()

print("Interactive 3D gradient descent visualization created with updated layout.")

"""# Improvement using SMOTE

Adjust the classification threshold of the current Logistic Regression model to experiment with different precision-recall trade-offs. Evaluate the model's performance with a new threshold, focusing on how recall for churners changes.

## Adjust Classification Threshold
"""

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report

# Define a new classification threshold
new_threshold = 0.3

# Convert predicted probabilities into binary predictions using the new threshold
y_pred_new_threshold = (y_pred_proba >= new_threshold).astype(int)

print(f"New classification threshold set to: {new_threshold}")
print("Binary predictions generated with new threshold.")

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report

# Calculate evaluation metrics with the new threshold
accuracy_new = accuracy_score(y_test, y_pred_new_threshold)
precision_new = precision_score(y_test, y_pred_new_threshold)
recall_new = recall_score(y_test, y_pred_new_threshold)
f1_new = f1_score(y_test, y_pred_new_threshold)
roc_auc_new = roc_auc_score(y_test, y_pred_proba) # ROC AUC uses probabilities, so it doesn't change with threshold

print(f"\nMetrics with new threshold ({new_threshold}):")
print(f"Accuracy: {accuracy_new:.4f}")
print(f"Precision: {precision_new:.4f}")
print(f"Recall: {recall_new:.4f}")
print(f"F1-Score: {f1_new:.4f}")
print(f"ROC AUC Score: {roc_auc_new:.4f}")

print("\nClassification Report with new threshold:")
print(classification_report(y_test, y_pred_new_threshold))

"""## Address Class Imbalance with SMOTE"""

from imblearn.over_sampling import SMOTE

print("SMOTE imported successfully.")

smote = SMOTE(random_state=42)

print("SMOTE object instantiated.")

X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

print("SMOTE applied to training data.")
print(f"Original training data shape: {X_train.shape}, {y_train.shape}")
print(f"Resampled training data shape: {X_resampled.shape}, {y_resampled.shape}")

print("Value counts of y_resampled after SMOTE:")
print(y_resampled.value_counts())

"""## Train Model with Balanced Data

**Reasoning**:
As per the first instruction, I will instantiate a `LogisticRegression` model with the best hyperparameters from the previous tuning step (`C=0.1`, `solver='lbfgs'`) and set `random_state=42` for reproducibility. Then, as per the second instruction, I will train this model using the SMOTE-resampled training data (`X_resampled`, `y_resampled`). Finally, as per the third instruction, the trained model will be implicitly stored in the `model_resampled` variable for future use.
"""

from sklearn.linear_model import LogisticRegression

# 1. Instantiate a LogisticRegression model with the best hyperparameters
model_resampled = LogisticRegression(C=0.1, solver='lbfgs', random_state=42)

# 2. Train this model using the SMOTE-resampled training data
model_resampled.fit(X_resampled, y_resampled)

print("Logistic Regression model trained on SMOTE-resampled data.")

"""## Evaluate Model with Balanced Data"""

import numpy as np

# Make predictions on the test set using the model trained on resampled data
y_pred_resampled = model_resampled.predict(X_test)

# Predict probabilities for the positive class (class 1)
y_pred_proba_resampled = model_resampled.predict_proba(X_test)[:, 1]

print("Predictions made on the test set using the model trained on SMOTE-resampled data.")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report

# Calculate evaluation metrics with the model trained on resampled data
accuracy_resampled = accuracy_score(y_test, y_pred_resampled)
precision_resampled = precision_score(y_test, y_pred_resampled)
recall_resampled = recall_score(y_test, y_pred_resampled)
f1_resampled = f1_score(y_test, y_pred_resampled)
roc_auc_resampled = roc_auc_score(y_test, y_pred_proba_resampled) # ROC AUC uses probabilities

print(f"\nMetrics with model trained on SMOTE-resampled data:")
print(f"Accuracy: {accuracy_resampled:.4f}")
print(f"Precision: {precision_resampled:.4f}")
print(f"Recall: {recall_resampled:.4f}")
print(f"F1-Score: {f1_resampled:.4f}")
print(f"ROC AUC Score: {roc_auc_resampled:.4f}")

print("\nClassification Report with model trained on SMOTE-resampled data:")
print(classification_report(y_test, y_pred_resampled))

"""## Re-evaluate Model Performance

### Comparison of Model Performance Metrics

To effectively compare the models, let's consolidate the key metrics, especially focusing on 'Churn' (class 1) recall and precision:

| Model Scenario                     | Accuracy | Precision (Churn) | Recall (Churn) | F1-Score (Churn) | ROC AUC |
|:-----------------------------------|:---------|:------------------|:---------------|:-----------------|:--------|
| **Initial LR Model**               | 0.8226   | 0.6990            | 0.5791         | 0.6334           | 0.8627  |
| **LR Model with Threshold 0.3**    | 0.7807   | 0.5602            | 0.7989         | 0.6586           | 0.8627  |
| **LR Model with SMOTE**            | 0.7644   | 0.5350            | 0.8391         | 0.6534           | 0.8628  |

**Discussion:**

1.  **Initial Logistic Regression Model:** This model provided a good balance of overall accuracy (0.8226) and a decent precision for churners (0.6990). However, its recall for the 'Churn' class was relatively low (0.5791), meaning it missed a significant portion of actual churners. This is a common issue with imbalanced datasets where the minority class is harder to detect.

2.  **Logistic Regression Model with Adjusted Threshold (0.3):** By lowering the classification threshold from the default 0.5 to 0.3, there was a noticeable shift in the model's performance:
    *   **Recall (Churn) significantly increased** from 0.5791 to 0.7989. This indicates the model is now much better at identifying actual churners.
    *   **Precision (Churn) significantly decreased** from 0.6990 to 0.5602. This implies that while more churners are caught, there are also more false positives (customers predicted to churn who do not).
    *   Overall **Accuracy decreased** to 0.7807, and the **F1-Score for churners slightly increased** to 0.6586, reflecting the improved balance between precision and recall for the minority class. The ROC AUC remained virtually unchanged, as it's threshold-independent.

3.  **Logistic Regression Model with SMOTE Oversampling:** Training the model on SMOTE-resampled data aimed to directly address the class imbalance in the training phase:
    *   **Recall (Churn) further improved** to 0.8391, making it the best among the three scenarios at identifying actual churners.
    *   **Precision (Churn) slightly decreased** compared to the adjusted threshold model, settling at 0.5350. This is the lowest precision among the three, suggesting more false positives than the other models.
    *   Overall **Accuracy was the lowest** at 0.7644, which is expected when optimizing for the minority class in an imbalanced dataset. The **F1-Score for churners was comparable** to the adjusted threshold model at 0.6534. The ROC AUC remained strong at 0.8628.

**Trade-offs:**

The comparison highlights a clear trade-off between **precision and recall** when dealing with imbalanced datasets and seeking to improve the detection of the minority class ('Churn').

*   **Adjusting the threshold** is a post-prediction technique that can effectively shift this balance. It's a quick way to prioritize recall if the cost of missing a churner is high, even if it means accepting more false alarms.
*   **SMOTE oversampling** directly modifies the training data distribution, leading the model to learn from a balanced representation of both classes. This often results in a model inherently biased towards better recall for the minority class. While it yields the highest recall for churn in this case, it also comes with the lowest precision and overall accuracy.

The choice between these approaches (or a combination) depends on the specific business objective. If identifying as many potential churners as possible is critical, even at the cost of higher false positives, then the SMOTE-trained model or the model with an adjusted threshold (e.g., 0.3) would be preferred. If minimizing false positives is paramount, the initial model with its higher precision might be more suitable, despite lower recall.

## Visualize Improved Performance
"""

from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay
import matplotlib.pyplot as plt

# Create a figure with three subplots
fig, axes = plt.subplots(1, 3, figsize=(20, 6))

# Plot the Confusion Matrix for model_resampled
ConfusionMatrixDisplay.from_estimator(model_resampled, X_test, y_test, cmap='Blues', ax=axes[0])
axes[0].set_title('Confusion Matrix (SMOTE Model)')

# Plot the ROC Curve for model_resampled
RocCurveDisplay.from_estimator(model_resampled, X_test, y_test, ax=axes[1])
axes[1].set_title('ROC Curve (SMOTE Model)')

# Plot the Precision-Recall Curve for model_resampled
PrecisionRecallDisplay.from_estimator(model_resampled, X_test, y_test, ax=axes[2])
axes[2].set_title('Precision-Recall Curve (SMOTE Model)')

# Adjust layout and display plots
plt.tight_layout()
plt.show()

"""# Improvement using Gradient Boosting Classifier

Implement and tune a Gradient Boosting Classifier (e.g., XGBoost or LightGBM) on the SMOTE-resampled training data (X_resampled, y_resampled) for the customer churn prediction task, focusing on optimizing metrics that balance precision and recall.

## Implement Gradient Boosting Classifier

Import the `LGBMClassifier` class from `lightgbm` to prepare for implementing the Gradient Boosting Classifier.
"""

from lightgbm import LGBMClassifier

print("LGBMClassifier imported successfully.")

"""Instantiate an `LGBMClassifier` object with `random_state=42` for reproducibility."""

lgbm_model = LGBMClassifier(random_state=42)

print("LGBMClassifier instantiated.")

"""Train the `lgbm_model` using the `X_resampled` and `y_resampled` data with the `.fit()` method."""

lgbm_model.fit(X_resampled, y_resampled)

print("LGBMClassifier trained on SMOTE-resampled data.")

"""## Tune Gradient Boosting Classifier"""

from sklearn.model_selection import GridSearchCV

# 1. Define a hyperparameter grid for LGBMClassifier
param_grid_lgbm = {
    'num_leaves': [20, 31, 40],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [100, 200, 300],
    'reg_alpha': [0.1, 0.5]
}

# 2. Initialize GridSearchCV
grid_search_lgbm = GridSearchCV(estimator=lgbm_model, param_grid=param_grid_lgbm, cv=5, scoring='f1', n_jobs=-1, verbose=1)

# 3. Fit the GridSearchCV object to the SMOTE-resampled training data
grid_search_lgbm.fit(X_resampled, y_resampled)

# 4. Print the best hyperparameters
print("Best hyperparameters found for LGBMClassifier:", grid_search_lgbm.best_params_)

# 5. Print the best cross-validation F1-score
print("Best cross-validation F1-score for LGBMClassifier:", grid_search_lgbm.best_score_)

best_lgbm_model = grid_search_lgbm.best_estimator_

# Make predictions on the test set
y_pred_lgbm = best_lgbm_model.predict(X_test)

# Predict probabilities for the positive class (class 1)
y_pred_proba_lgbm = best_lgbm_model.predict_proba(X_test)[:, 1]

print("Best LGBMClassifier estimator retrieved and predictions made on the test set.")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report

# Calculate evaluation metrics with the best LGBM model
accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)
precision_lgbm = precision_score(y_test, y_pred_lgbm)
recall_lgbm = recall_score(y_test, y_pred_lgbm)
f1_lgbm = f1_score(y_test, y_pred_lgbm)
roc_auc_lgbm = roc_auc_score(y_test, y_pred_proba_lgbm)

print(f"\nMetrics with Tuned LGBM Model:")
print(f"Accuracy: {accuracy_lgbm:.4f}")
print(f"Precision: {precision_lgbm:.4f}")
print(f"Recall: {recall_lgbm:.4f}")
print(f"F1-Score: {f1_lgbm:.4f}")
print(f"ROC AUC Score: {roc_auc_lgbm:.4f}")

print("\nClassification Report with Tuned LGBM Model:")
print(classification_report(y_test, y_pred_lgbm))

"""## Visualize New Model Performance"""

from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay
import matplotlib.pyplot as plt

# Create a figure with three subplots
fig, axes = plt.subplots(1, 3, figsize=(20, 6))

# Plot the Confusion Matrix for best_lgbm_model
ConfusionMatrixDisplay.from_estimator(best_lgbm_model, X_test, y_test, cmap='Blues', ax=axes[0])
axes[0].set_title('Confusion Matrix (Tuned LGBM Model)')

# Plot the ROC Curve for best_lgbm_model
RocCurveDisplay.from_estimator(best_lgbm_model, X_test, y_test, ax=axes[1])
axes[1].set_title('ROC Curve (Tuned LGBM Model)')

# Plot the Precision-Recall Curve for best_lgbm_model
PrecisionRecallDisplay.from_estimator(best_lgbm_model, X_test, y_test, ax=axes[2])
axes[2].set_title('Precision-Recall Curve (Tuned LGBM Model)')

# Adjust layout and display plots
plt.tight_layout()
plt.show()

"""## Evaluate New Model Performance

### Comparison of Model Performance Metrics (Including Tuned LGBM)

To effectively compare the models, let's consolidate the key metrics, especially focusing on 'Churn' (class 1) recall and precision:

| Model Scenario                     | Accuracy | Precision (Churn) | Recall (Churn) | F1-Score (Churn) | ROC AUC |
|:-----------------------------------|:---------|:------------------|:---------------|:-----------------|:--------|
| **Initial LR Model**               | 0.8226   | 0.6990            | 0.5791         | 0.6334           | 0.8627  |
| **LR Model with Threshold 0.3**    | 0.7807   | 0.5602            | 0.7989         | 0.6586           | 0.8627  |
| **Tuned LGBM Model with SMOTE**    | 0.7999   | 0.6091            | 0.6810         | 0.6430           | 0.8554  |

**Discussion:**

1.  **Initial Logistic Regression Model:** This model provided a good balance of overall accuracy (0.8226) and a decent precision for churners (0.6990). However, its recall for the 'Churn' class was relatively low (0.5791), meaning it missed a significant portion of actual churners. This is a common issue with imbalanced datasets where the minority class is harder to detect.

2.  **Logistic Regression Model with Adjusted Threshold (0.3):** By lowering the classification threshold from the default 0.5 to 0.3, there was a noticeable shift in the model's performance:
    *   **Recall (Churn) significantly increased** from 0.5791 to 0.7989. This indicates the model is now much better at identifying actual churners.
    *   **Precision (Churn) significantly decreased** from 0.6990 to 0.5602. This implies that while more churners are caught, there are also more false positives (customers predicted to churn who do not).
    *   Overall **Accuracy decreased** to 0.7807, and the **F1-Score for churners slightly increased** to 0.6586, reflecting the improved balance between precision and recall for the minority class. The ROC AUC remained virtually unchanged, as it's threshold-independent.

3.  **Tuned LGBM Model with SMOTE Oversampling:** Training this Gradient Boosting model on SMOTE-resampled data aimed to leverage its ability to handle complex relationships while addressing class imbalance:
    *   The LGBM model achieves a **recall (Churn) of 0.6810**, which is better than the initial Logistic Regression model but lower than the threshold-adjusted LR model or the SMOTE-trained LR model.
    *   Its **precision (Churn) is 0.6091**, which is lower than the initial LR model but higher than both the threshold-adjusted LR and SMOTE-trained LR models.
    *   The **F1-Score for churners is 0.6430**, placing it competitively among the models. Its overall **Accuracy is 0.7999**, a good balance between the initial high-accuracy model and the high-recall models. The ROC AUC is strong at 0.8554.

**Balanced Performance Highlight for Tuned LGBM Model:**

The Tuned LGBM Model with SMOTE strikes a more balanced approach between precision and recall for the 'Churn' class compared to the other models. While the adjusted threshold LR model achieved higher recall, it did so at the cost of significantly lower precision. Conversely, the initial LR had high precision but poor recall. The LGBM model offers a **better balance, providing improved recall over the initial LR model (from 0.5791 to 0.6810) without as significant a drop in precision as observed with the threshold-adjusted LR model (0.6091 vs. 0.5602).** This makes it a robust choice when both identifying churners and minimizing false positives are important.

# Feature Importance
"""

!pip install plt

import matplotlib.pyplot as play, plt
import lightgbm as lgb

# Create a figure to ensure it fits well on your screen
fig, ax = plt.subplots(figsize=(10, 8))

# Plot the feature importances using the 'gain' metric
lgb.plot_importance(best_lgbm_model,
                    importance_type='gain',
                    max_num_features=20,
                    ax=ax,
                    title='LGBM Feature Importance (Gain)')

# Adjust layout so labels don't get cut off
plt.tight_layout()
plt.show()

"""# Model Saving"""

import joblib

print("joblib imported successfully.")

import joblib

# Save the scaler object
joblib.dump(scaler, 'scaler.joblib')

# Save the encoder object
joblib.dump(encoder, 'encoder.joblib')

print("StandardScaler and OneHotEncoder objects saved successfully.")

joblib.dump(best_lgbm_model, 'best_lgbm_model.joblib')

print("Tuned LGBM model saved as 'best_lgbm_model.joblib'.")

"""# Test with Inputs

## Test : Interactive Input for Predictor
"""

user_input_data = {}

print("Please enter values for the following features to predict customer churn:")

user_input_data['gender'] = input("gender (Male/Female): ")
user_input_data['SeniorCitizen'] = input("SeniorCitizen (0 for No, 1 for Yes): ")
user_input_data['Partner'] = input("Partner (Yes/No): ")
user_input_data['Dependents'] = input("Dependents (Yes/No): ")
user_input_data['tenure'] = input("tenure (integer, e.g., 1 to 72): ")
user_input_data['PhoneService'] = input("PhoneService (Yes/No): ")
user_input_data['MultipleLines'] = input("MultipleLines (Yes/No/No phone service): ")
user_input_data['InternetService'] = input("InternetService (DSL/Fiber optic/No): ")
user_input_data['OnlineSecurity'] = input("OnlineSecurity (Yes/No/No internet service): ")
user_input_data['OnlineBackup'] = input("OnlineBackup (Yes/No/No internet service): ")
user_input_data['DeviceProtection'] = input("DeviceProtection (Yes/No/No internet service): ")
user_input_data['TechSupport'] = input("TechSupport (Yes/No/No internet service): ")
user_input_data['StreamingTV'] = input("StreamingTV (Yes/No/No internet service): ")
user_input_data['StreamingMovies'] = input("StreamingMovies (Yes/No/No internet service): ")
user_input_data['Contract'] = input("Contract (Month-to-month/One year/Two year): ")
user_input_data['PaperlessBilling'] = input("PaperlessBilling (Yes/No): ")
user_input_data['PaymentMethod'] = input("PaymentMethod (Electronic check/Mailed check/Bank transfer (automatic)/Credit card (automatic)): ")
user_input_data['MonthlyCharges'] = input("MonthlyCharges (float, e.g., 29.85): ")
user_input_data['TotalCharges'] = input("TotalCharges (float, e.g., 29.85): ")

# --- BEGIN FIX FOR INTERNETSERVICE CATEGORY MISMATCH ---
# Standardize 'InternetService' input to match 'Fiber optic' if 'Fiber' is entered
if user_input_data['InternetService'].lower() == 'fiber':
    user_input_data['InternetService'] = 'Fiber optic'
# --- END FIX ---

# --- BEGIN FIX FOR PAYMENTMETHOD CATEGORY MISMATCH ---
# Standardize 'PaymentMethod' input to match 'Bank transfer (automatic)' if 'Bank transfer' is entered
if user_input_data['PaymentMethod'].lower() == 'bank transfer':
    user_input_data['PaymentMethod'] = 'Bank transfer (automatic)'
# --- END FIX ---

# Convert numerical features to appropriate types
user_input_data['SeniorCitizen'] = int(user_input_data['SeniorCitizen'])
user_input_data['tenure'] = int(user_input_data['tenure'])
user_input_data['MonthlyCharges'] = float(user_input_data['MonthlyCharges'])
user_input_data['TotalCharges'] = float(user_input_data['TotalCharges'])

print("\nCollected user input:")
for key, value in user_input_data.items():
    print(f"{key}: {value} (type: {type(value).__name__})")

import pandas as pd
import numpy as np

# Convert user_input_data dictionary to a DataFrame
user_df = pd.DataFrame([user_input_data])

# Map 'Yes' to 1, 'No'/'No internet service' to 0 for addon columns in user_df
addon_cols_user = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']
for col in addon_cols_user:
    # Use .loc to avoid SettingWithCopyWarning
    user_df.loc[:, col] = user_df[col].map({'Yes': 1, 'No': 0, 'No internet service': 0})

# Create 'Num_Addon_Services' for user_df
user_df.loc[:, 'Num_Addon_Services'] = user_df[addon_cols_user].sum(axis=1)

# Create 'Has_Internet_No_Security' for user_df
user_df.loc[:, 'Has_Internet_No_Security'] = (
    (user_df['InternetService'] != 'No') &
    (user_df['OnlineSecurity'] == 0) &
    (user_df['TechSupport'] == 0)
).astype(int)

# One-hot encode categorical features using the fitted encoder
categorical_features_model = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'PaperlessBilling', 'PaymentMethod']

encoded_user_features = encoder.transform(user_df[categorical_features_model])
encoded_user_df = pd.DataFrame(encoded_user_features, columns=encoder.get_feature_names_out(categorical_features_model))

# Scale numerical features using the fitted scaler
numerical_features_to_scale_model = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Num_Addon_Services', 'Has_Internet_No_Security']

scaled_user_features = scaler.transform(user_df[numerical_features_to_scale_model])
scaled_user_df = pd.DataFrame(scaled_user_features, columns=numerical_features_to_scale_model)

# Concatenate all preprocessed features
processed_user_input = pd.concat([scaled_user_df, encoded_user_df], axis=1)

# Make a prediction
churn_prediction = best_lgbm_model.predict(processed_user_input)
churn_probability = best_lgbm_model.predict_proba(processed_user_input)[:, 1]

# Interpret the prediction
prediction_label = "Churn (Likely to leave)" if churn_prediction[0] == 1 else "No Churn (Likely to stay)"

print(f"\nPrediction for the entered customer:")
print(f"  - Predicted Churn Status: {prediction_label}")
print(f"  - Probability of Churn: {churn_probability[0]:.4f}")

"""## Direct Input Predictor using Json"""

customer_features = {
    'gender': 'Female',
    'SeniorCitizen': 0,
    'Partner': 'Yes',
    'Dependents': 'Yes',
    'tenure': 35,
    'PhoneService': 'Yes',
    'MultipleLines': 'No',
    'InternetService': 'Fiber optic',
    'OnlineSecurity': 'No',
    'OnlineBackup': 'Yes',
    'DeviceProtection': 'Yes',
    'TechSupport': 'No',
    'StreamingTV': 'No',
    'StreamingMovies': 'No',
    'Contract': 'Month-to-month',
    'PaperlessBilling': 'Yes',
    'PaymentMethod': 'Bank transfer (automatic)',
    'MonthlyCharges': 79.50,
    'TotalCharges': 2782.50
}

print("Customer features for prediction:")
for key, value in customer_features.items():
    print(f"{key}: {value} (type: {type(value).__name__})")

import pandas as pd
import numpy as np

# Convert customer_features dictionary to a DataFrame
user_df_direct = pd.DataFrame([customer_features])

# Ensure 'InternetService' and 'PaymentMethod' are consistent if specific short-forms are used (as in previous interactive input)
if 'InternetService' in user_df_direct.columns:
    user_df_direct.loc[user_df_direct['InternetService'].str.lower() == 'fiber', 'InternetService'] = 'Fiber optic'
if 'PaymentMethod' in user_df_direct.columns:
    user_df_direct.loc[user_df_direct['PaymentMethod'].str.lower() == 'bank transfer', 'PaymentMethod'] = 'Bank transfer (automatic)'

# Map 'Yes' to 1, 'No'/'No internet service' to 0 for addon columns in user_df_direct
addon_cols_direct = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']
for col in addon_cols_direct:
    user_df_direct.loc[:, col] = user_df_direct[col].map({'Yes': 1, 'No': 0, 'No internet service': 0})

# Create 'Num_Addon_Services' for user_df_direct
user_df_direct.loc[:, 'Num_Addon_Services'] = user_df_direct[addon_cols_direct].sum(axis=1)

# Create 'Has_Internet_No_Security' for user_df_direct
user_df_direct.loc[:, 'Has_Internet_No_Security'] = (
    (user_df_direct['InternetService'] != 'No') &
    (user_df_direct['OnlineSecurity'] == 0) &
    (user_df_direct['TechSupport'] == 0)
).astype(int)

# One-hot encode categorical features using the fitted encoder (encoder is from previous steps)
categorical_features_model = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'PaperlessBilling', 'PaymentMethod']

encoded_user_features_direct = encoder.transform(user_df_direct[categorical_features_model])
encoded_user_df_direct = pd.DataFrame(encoded_user_features_direct, columns=encoder.get_feature_names_out(categorical_features_model))

# Scale numerical features using the fitted scaler (scaler is from previous steps)
numerical_features_to_scale_model = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Num_Addon_Services', 'Has_Internet_No_Security']

scaled_user_features_direct = scaler.transform(user_df_direct[numerical_features_to_scale_model])
scaled_user_df_direct = pd.DataFrame(scaled_user_features_direct, columns=numerical_features_to_scale_model)

# Concatenate all preprocessed features
processed_user_input_direct = pd.concat([scaled_user_df_direct, encoded_user_df_direct], axis=1)

# Make a prediction using the best LGBM model (best_lgbm_model is from previous steps)
churn_prediction_direct = best_lgbm_model.predict(processed_user_input_direct)
churn_probability_direct = best_lgbm_model.predict_proba(processed_user_input_direct)[:, 1]

# Interpret the prediction
prediction_label_direct = "Churn (Likely to leave)" if churn_prediction_direct[0] == 1 else "No Churn (Likely to stay)"

print(f"\nPrediction for the entered customer:")
print(f"  - Predicted Churn Status: {prediction_label_direct}")
print(f"  - Probability of Churn: {churn_probability_direct[0]:.4f}")

"""## Demonstrate Deployment Prediction Flow"""

import joblib
import pandas as pd
import numpy as np

# 1, 2, 3, 4. Load the saved model, scaler, and encoder objects
loaded_lgbm_model = joblib.load('best_lgbm_model.joblib')
loaded_scaler = joblib.load('scaler.joblib')
loaded_encoder = joblib.load('encoder.joblib')

print("Model, scaler, and encoder loaded successfully.")

# 5. Define a new hypothetical customer's raw features
hypothetical_customer_features = {
    'gender': 'Male',
    'SeniorCitizen': 0,
    'Partner': 'Yes',
    'Dependents': 'No',
    'tenure': 24,
    'PhoneService': 'Yes',
    'MultipleLines': 'Yes',
    'InternetService': 'Fiber optic',
    'OnlineSecurity': 'No',
    'OnlineBackup': 'No',
    'DeviceProtection': 'Yes',
    'TechSupport': 'No',
    'StreamingTV': 'Yes',
    'StreamingMovies': 'Yes',
    'Contract': 'Month-to-month',
    'PaperlessBilling': 'Yes',
    'PaymentMethod': 'Electronic check',
    'MonthlyCharges': 90.00,
    'TotalCharges': 2160.00
}

print("\nHypothetical customer features defined:")
for key, value in hypothetical_customer_features.items():
    print(f"{key}: {value}")

# 6. Convert the dictionary into a Pandas DataFrame
predict_df = pd.DataFrame([hypothetical_customer_features])

# 7a. Map 'Yes' to 1, 'No'/'No internet service' to 0 for addon columns
addon_cols = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']
for col in addon_cols:
    predict_df.loc[:, col] = predict_df[col].map({'Yes': 1, 'No': 0, 'No internet service': 0})

# 7b. Create 'Num_Addon_Services' feature
predict_df.loc[:, 'Num_Addon_Services'] = predict_df[addon_cols].sum(axis=1)

# 7c. Create 'Has_Internet_No_Security' feature
predict_df.loc[:, 'Has_Internet_No_Security'] = (
    (predict_df['InternetService'] != 'No') &
    (predict_df['OnlineSecurity'] == 0) &
    (predict_df['TechSupport'] == 0)
).astype(int)

# 8. Identify categorical features and apply loaded encoder.transform()
categorical_features_model = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'PaperlessBilling', 'PaymentMethod']
encoded_predict_features = loaded_encoder.transform(predict_df[categorical_features_model])
encoded_predict_df = pd.DataFrame(encoded_predict_features, columns=loaded_encoder.get_feature_names_out(categorical_features_model))

# 9. Identify numerical features and apply loaded scaler.transform()
numerical_features_to_scale_model = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Num_Addon_Services', 'Has_Internet_No_Security']
scaled_predict_features = loaded_scaler.transform(predict_df[numerical_features_to_scale_model])
scaled_predict_df = pd.DataFrame(scaled_predict_features, columns=numerical_features_to_scale_model)

# 10. Concatenate preprocessed features
preprocessed_customer_data = pd.concat([scaled_predict_df, encoded_predict_df], axis=1)

# Ensure column order matches training data (important for consistent predictions)
# Get the feature names from the loaded model's training data (if available)
# For LGBMClassifier, we can get feature_name directly if it was set during training, or use the X_train columns
# Assuming loaded_lgbm_model was trained on preprocessed_df.drop('Churn', axis=1)
# X_train.columns from earlier in the notebook contains the correct order.
# To be safe, we reconstruct the column order based on known features and the encoder's output

# Get all feature names used during model training
# This assumes the feature names are consistent from the training phase.
# In this notebook, X_train is available, so we can use its columns.
# If X_train was not available, we would need to manually reconstruct the column order from scaler and encoder.

# Using X_train from the kernel state as it's the source for feature order
# Note: This relies on kernel state, in a real deployment, you'd save feature names or ensure strict ordering.
# For this demonstration, we'll assume the order of concatenation yields correct feature order.
# If column order mismatch, loaded_lgbm_model.feature_name_ or a stored list of feature names would be used to reindex.

# Verify column names match those expected by the model
# If the model expects specific columns in a specific order, we should reindex `preprocessed_customer_data`.
# For LightGBM, column order is generally not as critical as for some other models, but it's good practice.
# Assuming the order resulting from pd.concat matches the training order.

# 11. Make a churn prediction and predict churn probability
churn_prediction = loaded_lgbm_model.predict(preprocessed_customer_data)
churn_probability = loaded_lgbm_model.predict_proba(preprocessed_customer_data)[:, 1]

# 12. Print the predicted churn status and probability
prediction_label = "Churn (Likely to leave)" if churn_prediction[0] == 1 else "No Churn (Likely to stay)"

print(f"\nPrediction for the hypothetical customer:")
print(f"  - Predicted Churn Status: {prediction_label}")
print(f"  - Probability of Churn: {churn_probability[0]:.4f}")

"""# Backend

## main.py
"""

import joblib
import pandas as pd
import numpy as np
from fastapi import FastAPI
from pydantic import BaseModel
from typing import Literal, List
from fastapi.middleware.cors import CORSMiddleware

# 3. Load the saved model, scaler, and encoder objects into global variables
# Ensure these files are in the same directory as main.py or provide the correct path
loaded_lgbm_model = joblib.load('best_lgbm_model.joblib')
loaded_scaler = joblib.load('scaler.joblib')
loaded_encoder = joblib.load('encoder.joblib')

# Get feature names from the training data, assuming X_train columns were used
# In a real deployment, these would be saved along with the model or derived consistently.
# For this notebook context, we can assume the feature names from the X_train used before.
# This list should match the order and names of features that the model was trained on.
# This is a critical step for consistent predictions.
# Reconstruct X_train column names based on previous processing steps if not explicitly saved.

# Numerical features that were scaled
numerical_features_model_columns = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Num_Addon_Services', 'Has_Internet_No_Security']

# Categorical features that were one-hot encoded
categorical_features_for_encoder = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'PaperlessBilling', 'PaymentMethod']

# Get the feature names generated by the encoder
encoded_feature_names = loaded_encoder.get_feature_names_out(categorical_features_for_encoder)

# Combine all feature names in the correct order
MODEL_FEATURES = numerical_features_model_columns + list(encoded_feature_names)


print("Model, scaler, and encoder loaded successfully.")
print(f"Expected model features: {MODEL_FEATURES[:5]}... ({len(MODEL_FEATURES)} total)")

import joblib
import pandas as pd
import numpy as np
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import Literal, List
from fastapi.middleware.cors import CORSMiddleware

# 3. Load the saved model, scaler, and encoder objects into global variables
# Ensure these files are in the same directory as main.py or provide the correct path
loaded_lgbm_model = joblib.load('/content/best_lgbm_model.joblib')
loaded_scaler = joblib.load('/content/scaler.joblib')
loaded_encoder = joblib.load('/content/encoder.joblib')

# Numerical features that were scaled
numerical_features_model_columns = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Num_Addon_Services', 'Has_Internet_No_Security']

# Categorical features that were one-hot encoded
categorical_features_for_encoder = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'PaperlessBilling', 'PaymentMethod']

# Get the feature names generated by the encoder
encoded_feature_names = loaded_encoder.get_feature_names_out(categorical_features_for_encoder)

# Combine all feature names in the correct order for the model input
MODEL_FEATURES = numerical_features_model_columns + list(encoded_feature_names)


print("Model, scaler, and encoder loaded successfully.")
print(f"Expected model features: {MODEL_FEATURES[:5]}... ({len(MODEL_FEATURES)} total)")

# 4. Define a Pydantic BaseModel named CustomerData
class CustomerData(BaseModel):
    gender: Literal['Male', 'Female']
    SeniorCitizen: Literal[0, 1]
    Partner: Literal['Yes', 'No']
    Dependents: Literal['Yes', 'No']
    tenure: int = Field(..., ge=0, le=72)
    PhoneService: Literal['Yes', 'No']
    MultipleLines: Literal['Yes', 'No', 'No phone service']
    InternetService: Literal['DSL', 'Fiber optic', 'No']
    OnlineSecurity: Literal['Yes', 'No', 'No internet service']
    OnlineBackup: Literal['Yes', 'No', 'No internet service']
    DeviceProtection: Literal['Yes', 'No', 'No internet service']
    TechSupport: Literal['Yes', 'No', 'No internet service']
    StreamingTV: Literal['Yes', 'No', 'No internet service']
    StreamingMovies: Literal['Yes', 'No', 'No internet service']
    Contract: Literal['Month-to-month', 'One year', 'Two year']
    PaperlessBilling: Literal['Yes', 'No']
    PaymentMethod: Literal['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)']
    MonthlyCharges: float = Field(..., ge=0)
    TotalCharges: float = Field(..., ge=0)

# 5. Define a Pydantic BaseModel named PredictionResponse
class PredictionResponse(BaseModel):
    predicted_churn_status: str
    probability_of_churn: float
    risk_level: Literal['Low', 'Medium', 'High']
    recommendations: List[str]

# 6. Create a helper function, e.g., preprocess_input(customer_data: CustomerData)
def preprocess_input(customer_data: CustomerData) -> pd.DataFrame:
    # Convert the CustomerData into a pandas DataFrame
    user_df = pd.DataFrame([customer_data.model_dump()])

    # Replicate the feature engineering steps
    addon_cols_map = {'Yes': 1, 'No': 0, 'No internet service': 0}
    addon_cols = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']

    for col in addon_cols:
        user_df.loc[:, col] = user_df[col].map(addon_cols_map)

    user_df.loc[:, 'Num_Addon_Services'] = user_df[addon_cols].sum(axis=1)

    user_df.loc[:, 'Has_Internet_No_Security'] = (
        (user_df['InternetService'] != 'No') &
        (user_df['OnlineSecurity'] == 0) &
        (user_df['TechSupport'] == 0)
    ).astype(int)

    # Ensure categorical features are explicitly string type before encoding
    for col in categorical_features_for_encoder:
        user_df.loc[:, col] = user_df[col].astype(str)

    # Use the loaded OneHotEncoder to preprocess categorical features.
    # Ensure the order of categorical features for encoding matches the training.
    encoded_user_features = loaded_encoder.transform(user_df[categorical_features_for_encoder])
    encoded_user_df = pd.DataFrame(encoded_user_features, columns=loaded_encoder.get_feature_names_out(categorical_features_for_encoder))

    # Use the loaded StandardScaler to preprocess numerical features.
    scaled_user_features = loaded_scaler.transform(user_df[numerical_features_model_columns])
    scaled_user_df = pd.DataFrame(scaled_user_features, columns=numerical_features_model_columns)

    # Concatenate the processed features and ensure column order matches MODEL_FEATURES
    preprocessed_data_df = pd.concat([scaled_user_df, encoded_user_df], axis=1)

    # Ensure column order matches the training data by reindexing
    preprocessed_data_df = preprocessed_data_df.reindex(columns=MODEL_FEATURES, fill_value=0)

    return preprocessed_data_df

# 7. Instantiate the FastAPI application
app = FastAPI()

# 8. Configure CORSMiddleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000"], # Adjust for your frontend URL(s)
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"]
)

# 9. Implement a POST endpoint '/predict'
@app.post("/predict", response_model=PredictionResponse)
async def predict_churn(customer_data: CustomerData):
    try:
        # Preprocess the input data
        processed_input = preprocess_input(customer_data)

        # Make a prediction
        churn_probability = loaded_lgbm_model.predict_proba(processed_input)[:, 1][0]
        predicted_churn = (churn_probability >= 0.5).astype(int) # Default threshold of 0.5

        # Determine risk level and recommendations
        if predicted_churn == 1:
            predicted_churn_status = "Churn (Likely to leave)"
            risk_level = "High"
            recommendations = [
                "Offer a special retention discount or package.",
                "Contact customer to understand dissatisfaction points.",
                "Highlight benefits of current services."
            ]
            if customer_data.Contract == 'Month-to-month':
                recommendations.append("Propose switching to a longer-term contract with incentives.")
            if customer_data.MonthlyCharges > 100: # Example threshold for high charges
                 recommendations.append("Review pricing and competitive offers.")
            if customer_data.TechSupport == 'No':
                 recommendations.append("Offer free premium tech support for a limited period.")
        else:
            predicted_churn_status = "No Churn (Likely to stay)"
            risk_level = "Low"
            recommendations = [
                "Continue to monitor customer satisfaction.",
                "Consider upselling relevant add-on services.",
                "Reward loyalty with occasional perks."
            ]
            if customer_data.Contract == 'Month-to-month':
                recommendations.append("Encourage migration to longer-term contracts to secure loyalty.")

        return PredictionResponse(
            predicted_churn_status=predicted_churn_status,
            probability_of_churn=churn_probability,
            risk_level=risk_level,
            recommendations=recommendations
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

"""## Project File Structure

To ensure clarity and maintainability, the project will follow a standard file structure for both the FastAPI backend and the frontend.

```
churn-predictor/
 backend/                     # FastAPI Backend
    main.py                  # FastAPI application, loads models, preprocesses, predicts
    best_lgbm_model.joblib   # Saved LightGBM model
    scaler.joblib            # Saved StandardScaler object
    encoder.joblib           # Saved OneHotEncoder object
    requirements.txt         # Python dependencies (fastapi, uvicorn, scikit-learn, lightgbm, pandas, numpy)

 frontend/                    # React Frontend (Vite/TypeScript)
    public/
       index.html           # Main HTML file
    src/
       main.tsx             # React application entry point
       predictionApi.ts     # API client for backend communication
    tsconfig.json            # TypeScript configuration
    vite.config.ts           # Vite configuration

 README.md                    # Project overview and setup instructions
 .gitignore                   # Files to ignore in Git
```
"""